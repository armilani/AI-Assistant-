import base64
import os
import subprocess
import time
from threading import Lock, Thread
import cv2
import openai
from cv2 import VideoCapture, imencode
from dotenv import load_dotenv
from pyaudio import PyAudio, paInt16
from speech_recognition import Microphone, Recognizer, UnknownValueError

load_dotenv()
openai.api_key = "API KEY"

class WebcamStream:
    def __init__(self):
        self.stream = VideoCapture(0)
        self.running = False
        self.lock = Lock()
        _, self.frame = self.stream.read()

    def start(self):
        if self.running:
            return self
        self.running = True
        self.thread = Thread(target=self.update, args=())
        self.thread.start()
        return self

    def update(self):
        while self.running:
            _, frame = self.stream.read()
            with self.lock:
                self.frame = frame

    def read(self, encode=False):
        with self.lock:
            frame = self.frame.copy()
        if encode:
            _, buffer = imencode(".jpeg", frame)
            return base64.b64encode(buffer)
        return frame

    def stop(self):
        self.running = False
        if self.thread.is_alive():
            self.thread.join()

    def __exit__(self, exc_type, exc_value, exc_traceback):
        self.stream.release()

class Assistant:
    def __init__(self):
        self.chat_history = []

    def answer(self, prompt, image):
        if not prompt:
            return
        combined_prompt = f"{self._create_inference_chain()}\nUser: {prompt}. The image shows: [IMAGE]."
        try:
            response = self.__retry_openai_call(combined_prompt)
            if response:
                self.chat_history.append({"user": prompt, "assistant": response})
                self._tts(response)
        except Exception as e:
            print(f"An error occurred: {e}")

    def __retry_openai_call(self, combined_prompt, retries=5):
        for i in range(retries):
            try:
                response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": self._create_inference_chain()},
                        {"role": "user", "content": combined_prompt}
                    ],
                    max_tokens=100,
                    n=1,
                    stop=None,
                    temperature=0.7,
                )
                print(f"Response: {response.choices[0].message['content'].strip()}")
                return response.choices[0].message['content'].strip()
            except Exception as e:
                print(f"OpenAI API error: {e}")
                if i < retries - 1:
                    time.sleep(2 ** i)
                else:
                    return None

    def _create_inference_chain(self):
        SYSTEM_PROMPT = """
        You are a witty assistant that will use the chat history and the image 
        provided by the user to answer its questions.
        Use few words in your answers. Go straight to the point. Do not use any
        emoticons or emojis. Do not ask the user any questions.
        Be friendly and helpful. Show some personality. Do not be too formal.
        """
        chat_history_str = "\n".join([f"User: {msg['user']}\nAssistant: {msg['assistant']}" for msg in self.chat_history])
        return f"{SYSTEM_PROMPT}\n{chat_history_str}"

    def _tts(self, response):
        try:
            subprocess.call(['say', response])
        except Exception as e:
            print(f"TTS error: {e}")

def audio_callback(recognizer, audio):
    try:
        prompt = recognizer.recognize_google(audio)
        if prompt:
            print(f"Recognized speech: {prompt}")
            assistant.answer(prompt, webcam_stream.read(encode=True))
        else:
            print("Could not understand the audio")
    except UnknownValueError:
        print("Could not understand the audio")
    except Exception as e:
        print(f"Error: {e}")

webcam_stream = WebcamStream().start()
assistant = Assistant()
recognizer = Recognizer()
microphone = Microphone()

with microphone as source:
    recognizer.adjust_for_ambient_noise(source)

stop_listening = recognizer.listen_in_background(microphone, audio_callback)

try:
    while True:
        cv2.imshow("Webcam", webcam_stream.read())
        if cv2.waitKey(1) in [27, ord("q")]:  # Press 'q' or 'Esc' to exit
            break
except KeyboardInterrupt:
    print("Program interrupted by user")
finally:
    webcam_stream.stop()
    cv2.destroyAllWindows()
    stop_listening(wait_for_stop=False)
